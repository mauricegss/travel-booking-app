import os
from dotenv import load_dotenv
from typing import TypedDict, Annotated
import operator

# Importa√ß√µes espec√≠ficas do LangChain e Google GenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.graph import StateGraph, END

# Importa as fun√ß√µes mock das ferramentas (embora n√£o sejam usadas diretamente neste exemplo inicial)
from app.tools.flight_tools import search_flights
from app.tools.hotel_tools import search_hotels
from app.tools.activity_tools import search_activities
from app.tools.booking_tools import confirm_booking, process_payment

# --- Configura√ß√£o Inicial ---

# Carrega as vari√°veis de ambiente (especialmente a GOOGLE_API_KEY do arquivo .env no diret√≥rio backend)
# __file__ se refere a este arquivo (langgraph_app.py)
# os.path.dirname obt√©m o diret√≥rio (backend/app)
# os.path.join monta o caminho para o diret√≥rio backend
dotenv_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env')
load_dotenv(dotenv_path=dotenv_path)

# Verifica se a chave da API do Google est√° configurada
if 'GOOGLE_API_KEY' not in os.environ:
    print("Erro: A vari√°vel de ambiente GOOGLE_API_KEY n√£o foi definida.")
    print(f"Por favor, crie um arquivo .env no diret√≥rio '{os.path.dirname(dotenv_path)}' e adicione sua chave.")
    exit()
else:
    print("GOOGLE_API_KEY carregada com sucesso.")


# Inicializa o modelo LLM (Gemini 1.5 Pro)
# Usamos uma temperatura baixa (0.2) para respostas mais consistentes
try:
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro-latest", temperature=0.2)
    print("Modelo ChatGoogleGenerativeAI inicializado com sucesso.")
except Exception as e:
    print(f"Erro ao inicializar o ChatGoogleGenerativeAI: {e}")
    print("Verifique sua GOOGLE_API_KEY e a instala√ß√£o das bibliotecas.")
    exit()

# --- Defini√ß√£o do Estado do Grafo ---

# O "Estado" √© o objeto central que todos os agentes ir√£o ler e modificar.
class TravelAppState(TypedDict):
    user_request: str  # O pedido original do usu√°rio
    destination: str | None # Destino extra√≠do (pode ser adicionado por um n√≥ futuro)
    start_date: str | None # Data de in√≠cio extra√≠da
    end_date: str | None   # Data de fim extra√≠da
    flights: str       # A resposta do agente de voos
    hotels: str        # A resposta do agente de hospedagem
    activities: str    # A resposta do agente de atividades
    itinerary: str     # O itiner√°rio final consolidado

# --- Defini√ß√£o dos Agentes (N√≥s do Grafo) ---

# Cada agente √© uma fun√ß√£o (um "n√≥" no grafo) que recebe o estado atual,
# executa sua l√≥gica (simulada pelo LLM aqui) e retorna um dicion√°rio
# para atualizar o estado.

def flight_agent_node(state: TravelAppState) -> dict:
    """
    Agente simulado para encontrar voos.
    """
    print("--- ‚úàÔ∏è Agente de Voos: Buscando op√ß√µes ---")
    user_request = state['user_request']

    system_prompt = """
    Voc√™ √© um agente de viagens especialista em encontrar voos. Sua tarefa √© encontrar
    as 2-3 melhores op√ß√µes de voos (ida e volta) para o pedido do usu√°rio.
    Seja conciso, mas inclua companhia a√©rea (fict√≠cia), hor√°rios aproximados e pre√ßo m√©dio.
    Responda APENAS com as op√ß√µes de voos. Extraia o destino principal do pedido do usu√°rio.
    Formato esperado da resposta (exemplo):
    Destino Principal: Paris
    Op√ß√µes de Voos:
    - Op√ß√£o 1...
    - Op√ß√£o 2...
    """

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_request)
    ]

    response = llm.invoke(messages)
    # TODO: Extrair o 'Destino Principal' da resposta e atualizar state['destination']
    return {"flights": response.content}

def hotel_agent_node(state: TravelAppState) -> dict:
    """
    Agente simulado para encontrar hospedagem.
    """
    print("--- üè® Agente de Hospedagem: Pesquisando hot√©is ---")
    user_request = state['user_request']
    # Idealmente, usaria state['destination'], state['start_date'], state['end_date'] se extra√≠dos

    system_prompt = """
    Voc√™ √© um agente de viagens especialista em hospedagem com base no destino.
    Sua tarefa √© sugerir 3 op√ß√µes de hot√©is que se encaixem no pedido do usu√°rio,
    cobrindo diferentes faixas de pre√ßo (Luxo, Conforto, Econ√¥mico).
    Inclua o nome do hotel (fict√≠cio), uma breve descri√ß√£o e pre√ßo m√©dio por noite.
    Responda APENAS com as op√ß√µes de hot√©is.
    """

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_request) # Poderia passar infos mais espec√≠ficas do estado
    ]

    response = llm.invoke(messages)
    return {"hotels": response.content}

def activity_agent_node(state: TravelAppState) -> dict:
    """
    Agente simulado para sugerir atividades locais.
    """
    print("--- üó∫Ô∏è Agente de Atividades: Sugerindo passeios ---")
    user_request = state['user_request']
    # Idealmente, usaria state['destination']

    system_prompt = """
    Voc√™ √© um guia tur√≠stico local entusiasmado e experiente no destino do usu√°rio.
    Sua tarefa √© recomendar 5 atividades ou atra√ß√µes imperd√≠veis.
    Inclua uma mistura de pontos tur√≠sticos famosos e "joias escondidas".
    Responda APENAS com a lista de atividades.
    """

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_request) # Poderia passar infos mais espec√≠ficas do estado
    ]

    response = llm.invoke(messages)
    return {"activities": response.content}

def integration_agent_node(state: TravelAppState) -> dict:
    """
    Agente final simulado que consolida todas as informa√ß√µes em um itiner√°rio.
    """
    print("--- üßæ Agente de Integra√ß√£o: Montando o itiner√°rio final ---")

    summary_prompt = f"""
    Voc√™ √© o agente de integra√ß√£o mestre. Sua tarefa √© pegar as informa√ß√µes
    coletadas pelos outros agentes e apresent√°-las ao usu√°rio de forma clara,
    organizada e amig√°vel, como um plano de viagem completo.

    O pedido original do usu√°rio foi:
    {state['user_request']}

    Informa√ß√µes de Voos:
    {state['flights']}

    Informa√ß√µes de Hospedagem:
    {state['hotels']}

    Sugest√µes de Atividades:
    {state['activities']}

    Compile tudo isso em um √∫nico itiner√°rio. Adicione uma sauda√ß√£o amig√°vel
    e uma frase de encerramento (ex: "Qualquer altera√ß√£o, basta me avisar!").
    Certifique-se de apresentar um plano coeso e l√≥gico.
    """

    print("--- ü§ñ Processando o itiner√°rio completo... (Isso pode levar um momento) ---")

    messages = [
        SystemMessage(content="Voc√™ √© um agente de viagens s√™nior montando um plano final."),
        HumanMessage(content=summary_prompt)
    ]

    response = llm.invoke(messages)
    return {"itinerary": response.content}

# --- Constru√ß√£o do Grafo (Workflow) ---

print("Construindo o gr√°fico de agentes LangGraph...")
workflow = StateGraph(TravelAppState)

# Adicionar os n√≥s
workflow.add_node("flights", flight_agent_node)
workflow.add_node("hotels", hotel_agent_node)
workflow.add_node("activities", activity_agent_node)
workflow.add_node("integrator", integration_agent_node)

# Definir as arestas (fluxo sequencial simples neste exemplo)
workflow.set_entry_point("flights")
workflow.add_edge("flights", "hotels")
workflow.add_edge("hotels", "activities")
workflow.add_edge("activities", "integrator")
workflow.add_edge("integrator", END)

# Compilar o gr√°fico
app = workflow.compile()
print("Gr√°fico compilado com sucesso.")

# --- Execu√ß√£o Principal (se o script for rodado diretamente) ---

if __name__ == "__main__":
    print("\n--- Iniciando Planejamento da Viagem (Execu√ß√£o Direta) ---")

    # Exemplo de input
    user_input = "Planeje uma viagem de S√£o Paulo a T√≥quio, 7 dias em abril."

    initial_state = {
        "user_request": user_input,
        "destination": None,
        "start_date": None,
        "end_date": None,
        "flights": "", # Inicializa strings vazias para evitar erros
        "hotels": "",
        "activities": "",
        "itinerary": ""
        }

    # Invocar o gr√°fico
    try:
        final_response_state = app.invoke(initial_state)

        print("\n--- Planejamento Conclu√≠do! ---")

        # Exibir o resultado final
        print("\n" + "="*50)
        print("             ITINER√ÅRIO FINAL GERADO")
        print("="*50 + "\n")
        print(final_response_state.get('itinerary', "Nenhum itiner√°rio gerado.")) # Usar .get para seguran√ßa
        print("\n" + "="*50 + "\n")

    except Exception as e:
        print(f"\nErro durante a execu√ß√£o do gr√°fico: {e}")
        import traceback
        traceback.print_exc()